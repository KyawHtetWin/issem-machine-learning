{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMhRvuqHMYMJK4Wztzg8hVm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Introduction\n","\n","In this notebook, I implement a neural network from scratch using PyTorch.I will implement it while training a digit classifier that can recognizes 10 handwritten digits. The dataset that I am using is the popular MNIST dataset.\n","\n","Now, let's get started by loading the dataset from Fast AI's library."],"metadata":{"id":"C4eErGj1ntu5"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"CbLUK3z0ngKr","executionInfo":{"status":"ok","timestamp":1706053413369,"user_tz":480,"elapsed":14842,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"outputs":[],"source":["!pip install fastai -q"]},{"cell_type":"code","source":["from fastai.vision.all import *"],"metadata":{"id":"iuQUUO6Ap3Ol","executionInfo":{"status":"ok","timestamp":1706053424597,"user_tz":480,"elapsed":11233,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["Fast AI has a handy helper function to download and extract from the URL."],"metadata":{"id":"ewfUG5iSqS-H"}},{"cell_type":"code","source":["path = untar_data(URLs.MNIST)"],"metadata":{"id":"lOIc_pbTp5z2","colab":{"base_uri":"https://localhost:8080/","height":37},"executionInfo":{"status":"ok","timestamp":1706053442184,"user_tz":480,"elapsed":17590,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"dac7ef8f-5d53-436e-bb4b-e84eb500870b"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      <progress value='15687680' class='' max='15683414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      100.03% [15687680/15683414 00:00&lt;00:00]\n","    </div>\n","    "]},"metadata":{}}]},{"cell_type":"code","source":["Path.BASE_PATH = path"],"metadata":{"id":"8RQa6xPgp_n_","executionInfo":{"status":"ok","timestamp":1706053442185,"user_tz":480,"elapsed":20,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Listing the content inside the path object, there are two directories where the images are grouped into training and test dataset."],"metadata":{"id":"NnBMYVKoqi2z"}},{"cell_type":"code","source":["path.ls()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IkG9cs0wqKsK","executionInfo":{"status":"ok","timestamp":1706053444570,"user_tz":480,"elapsed":170,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"e2c49898-17e9-4ea7-a46e-b115e3c6a41f"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(#2) [Path('training'),Path('testing')]"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["Exploring what's inside the training directory, we see that each digit has its own directory. So the labels that we want to predict is indicated by the name of this sub-directory.\n","\n"],"metadata":{"id":"FsPOICeIq_MI"}},{"cell_type":"code","source":["paths = (path / 'training').ls().sorted()\n","paths"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"umsvN7HIqgqA","executionInfo":{"status":"ok","timestamp":1706053478502,"user_tz":480,"elapsed":371,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"77711f63-0338-489c-a67d-b66511824c0d"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(#10) [Path('training/0'),Path('training/1'),Path('training/2'),Path('training/3'),Path('training/4'),Path('training/5'),Path('training/6'),Path('training/7'),Path('training/8'),Path('training/9')]"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["Before loading the entire dataset, let's see a couple of the images."],"metadata":{"id":"Vrmyn4QTvxV6"}},{"cell_type":"code","source":["zeros  = (path / 'training' / '0').ls()\n","Image.open(zeros[-1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":45},"id":"4yfBhfbLrHmn","executionInfo":{"status":"ok","timestamp":1706053499678,"user_tz":480,"elapsed":157,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"bb774803-4ca1-4874-adcb-f07f260c3a91"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABCElEQVR4nM2RPUoDURSFvzEWFtNlipSCI7FTLER0D+oGIlmBCII2IoJNFNEdBBSsNBbWamVjkUICFoZ0ShqLUQSF4yUWb8bMTLKAnOJxL9/94zwYMXm5fDI4Aq/2GA0rNkky7Q1Bi+cxfL8YYGuRYqjX5ezO8KYMY58NmF4CCqmuiYNnSepUgFJTUnrkqUzSFQBznSRy2vyRqT3vA1CVtA6MOxZUCnB4+QQwsx1mzgy3zKxddsmu9czu+rAqqetY6f5L9n0824fX8RLYP5HU3EiPNenB/3eotUMO3kJQj2RSayrrW8/MzD0f9WKWJX8hdc8WyKsRw/SRJMb7xdUVvNrL2+9A30jpD2aLlq1mErsXAAAAAElFTkSuQmCC\n"},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["fives = (path/'training'/'5').ls()\n","im = Image.open(fives[-1])\n","im"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":45},"id":"iIvzhLSmupTr","executionInfo":{"status":"ok","timestamp":1706053548062,"user_tz":480,"elapsed":188,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"9e1f2883-d682-4329-a296-e118248464b7"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA6klEQVR4nM2RMUoDYRCFZxeLFBYp0+3ewPRZIqRK5w10wQMIVlZCCIhF9AJGrCVYCiIsiNhaqY3a+QcE8QQfj1hoimXn71I41QzfzJs3jNk/i6RedoYXR2/2UNx8Nlvbtwh41uPeWoNVIADBSdes1nDWN7ub7polx6/2XR8sAk/bEW/FQhr5qD0L+ui3fFaBJhHNGVBtRPYFwA62XFhK0kJ6KR3YuX4Pv/ePXU/54RWAzjdd7fUsuwxi6t9jZj1BtizSZdK9L83MkjRNmyP5nHycDyOyp3/f+vIMtUYCmA98Mzv7QC9mdXXxA0wrceSs7XonAAAAAElFTkSuQmCC\n"},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["The types of these images are PIL object."],"metadata":{"id":"ol_h2SDryFFk"}},{"cell_type":"code","source":["type(im)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Iy1iN1ux8BV","executionInfo":{"status":"ok","timestamp":1706053589522,"user_tz":480,"elapsed":176,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"54edb6ac-86aa-4f2c-f6a9-a92b4583cf21"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PIL.PngImagePlugin.PngImageFile"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["Instead, we want to covert them into PyTorch's tensor using the `tensor` method.\n","\n","Each grey-scale image is represented by a 28x28 matrix of pixel vaues where they range from 0-25 (black to white).\n","\n","Below you see a small section of these pixel values."],"metadata":{"id":"jGBGcmMpt-35"}},{"cell_type":"code","source":["t = tensor(im)\n","t.shape, t[5:10, 10:15]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z5CAj0FiyWn6","executionInfo":{"status":"ok","timestamp":1706053736437,"user_tz":480,"elapsed":149,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"d1ae20c4-96db-436e-9c7c-998bf0c8a3aa"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([28, 28]),\n"," tensor([[  0,   0,   0,   0,  24],\n","         [  0,   0,   0,  16, 186],\n","         [  0,   0,  16, 189, 251],\n","         [  0,   0, 171, 251, 251],\n","         [  0,  60, 228, 251, 211]], dtype=torch.uint8))"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["Create a list containing the images as tensors and their labels from training dataset."],"metadata":{"id":"4gxyOPVru6wM"}},{"cell_type":"code","source":["train_xs = []\n","train_ys = []\n","tot = 0\n","for i, p in enumerate(paths):\n","  digit_paths = p.ls()\n","  num_digits = len(digit_paths)\n","  tot += num_digits\n","  train_ys += tensor([i] * num_digits)\n","  train_xs.extend([tensor(Image.open(f)) for f in digit_paths])"],"metadata":{"id":"uEtP1ZKmxFiH","executionInfo":{"status":"ok","timestamp":1706053885215,"user_tz":480,"elapsed":12030,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["Let's sense check the total number of images, and the size of an individual elements in our xs and ys.\n","\n","There are a total of 60,000 images and each image is a 28x28 pixel image and the label of the first image digit is zero."],"metadata":{"id":"QsvPgyO81xN-"}},{"cell_type":"code","source":["len(train_xs), len(train_ys), train_xs[0].shape, train_ys[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n874X0JU0zg7","executionInfo":{"status":"ok","timestamp":1706053912317,"user_tz":480,"elapsed":175,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"ce09eefa-c045-4726-863c-9d17b0ae791c"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 60000, torch.Size([28, 28]), tensor(0))"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["Now we can load the test data with the same code.\n","\n","The size of the test dataset is 10,000."],"metadata":{"id":"ZmMVnGEy2mHl"}},{"cell_type":"code","source":["test_paths = (path/'testing').ls().sorted()\n","test_xs = []\n","test_ys = []\n","tot_test = 0\n","for i, p in enumerate(test_paths):\n","  digit_paths = p.ls()\n","  num_digits = len(digit_paths)\n","  tot_test += num_digits\n","  test_ys += tensor([i] * num_digits)\n","  test_xs.extend([tensor(Image.open(f)) for f in digit_paths])"],"metadata":{"id":"BjICBXMp1iYN","executionInfo":{"status":"ok","timestamp":1706053946856,"user_tz":480,"elapsed":1997,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["len(test_xs), len(test_ys), test_xs[0].shape, test_ys[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4oadyMOH4hwY","executionInfo":{"status":"ok","timestamp":1706053950985,"user_tz":480,"elapsed":146,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"320393e4-817f-4fb0-9eb3-3a93d1d2c46a"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 10000, torch.Size([28, 28]), tensor(0))"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["# Preparing the data\n","\n","Now that the data is loaded is a list of PyTorch, what we want to do next is to represent the entire dataset as PyTorch. For example, the training dataset is a tesnor of shape (60_000, 28, 28) and the training label is a tensor of shape (60_000, 1).\n","\n","We can stack each of the digit on a row using the `stack` method, which works as follow:"],"metadata":{"id":"_-6oRB6Y4Uen"}},{"cell_type":"code","source":["import torch"],"metadata":{"id":"43rM0juk6xHY","executionInfo":{"status":"ok","timestamp":1706054026121,"user_tz":480,"elapsed":155,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["a, b = tensor([2, 2]), tensor([9, 10])\n","torch.stack([a, b], dim=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3_Y2gVaQ1koN","executionInfo":{"status":"ok","timestamp":1706054030316,"user_tz":480,"elapsed":183,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"55bb7fb4-867a-4d50-f5a1-b3063fcbd579"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 2,  2],\n","        [ 9, 10]])"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["Let's convert our training and test dataset from list to tensors."],"metadata":{"id":"Xq0xF1Go8Osj"}},{"cell_type":"code","source":["xs_train, ys_train = torch.stack(train_xs, dim=0), torch.stack(train_ys)\n","xs_test, ys_test = torch.stack(test_xs), torch.stack(test_ys)"],"metadata":{"id":"dWNbrke95MOt","executionInfo":{"status":"ok","timestamp":1706054050286,"user_tz":480,"elapsed":334,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["Checking the shape."],"metadata":{"id":"qTCyLQI38Y_n"}},{"cell_type":"code","source":["xs_train.shape, ys_train.shape, xs_test.shape, ys_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1CXz_hul7IfT","executionInfo":{"status":"ok","timestamp":1706054066007,"user_tz":480,"elapsed":181,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"6e90bfb9-40d6-4113-f492-220963e3f4c6"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([60000, 28, 28]),\n"," torch.Size([60000]),\n"," torch.Size([10000, 28, 28]),\n"," torch.Size([10000]))"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["If you recall from earlier, the pixel values are integer and cover a wide range of numbers."],"metadata":{"id":"i7YiuKqJ9Jdm"}},{"cell_type":"code","source":["xs_train[0, 5:15, 5:15]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bwug__mf8fLo","executionInfo":{"status":"ok","timestamp":1706054099878,"user_tz":480,"elapsed":179,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"c02d7661-05fc-4817-bfc1-5b28d3fdd114"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[  0,   0,   0,   0,   0,  25, 231, 252, 252, 252],\n","        [  0,   0,   0,   0,  14, 131, 252, 252, 252, 252],\n","        [  0,   0,   0,   0, 223, 252, 252, 252, 252, 252],\n","        [  0,   0,   5, 145, 248, 252, 252, 252, 252, 207],\n","        [  0,   0, 121, 252, 252, 252, 252, 241, 195,  30],\n","        [  0,  32, 210, 252, 252, 252, 252,  84,   0,   0],\n","        [  0, 113, 252, 252, 252, 241,  84,   1,   0,   0],\n","        [ 19, 216, 252, 252, 252, 108,   0,   0,   0,   0],\n","        [105, 252, 252, 252, 207,  30,   0,   0,   0,   0],\n","        [106, 253, 253, 253, 117,   0,   0,   0,   0,   0]], dtype=torch.uint8)"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["However, the issue is that neural networks work better with smaller decimal numbers.\n","\n","Since we know that 255 is the maximum pixel values, we will scale each of these pixel values to be in the range of 0-1 by dividing each of the values by its maximum (A process known as **normalization**)."],"metadata":{"id":"Ic5E_EFR9QXO"}},{"cell_type":"code","source":["xs_train = xs_train.float() / 255\n","xs_test = xs_test.float() / 255"],"metadata":{"id":"7VxtdJ5w9AZY","executionInfo":{"status":"ok","timestamp":1706054203112,"user_tz":480,"elapsed":659,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["xs_train[0, 5:15, 5:15]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9bBY1tWq-K70","executionInfo":{"status":"ok","timestamp":1706054204586,"user_tz":480,"elapsed":159,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"339424d0-d85f-483a-f6a1-f3059eae8d8a"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0980, 0.9059, 0.9882, 0.9882,\n","         0.9882],\n","        [0.0000, 0.0000, 0.0000, 0.0000, 0.0549, 0.5137, 0.9882, 0.9882, 0.9882,\n","         0.9882],\n","        [0.0000, 0.0000, 0.0000, 0.0000, 0.8745, 0.9882, 0.9882, 0.9882, 0.9882,\n","         0.9882],\n","        [0.0000, 0.0000, 0.0196, 0.5686, 0.9725, 0.9882, 0.9882, 0.9882, 0.9882,\n","         0.8118],\n","        [0.0000, 0.0000, 0.4745, 0.9882, 0.9882, 0.9882, 0.9882, 0.9451, 0.7647,\n","         0.1176],\n","        [0.0000, 0.1255, 0.8235, 0.9882, 0.9882, 0.9882, 0.9882, 0.3294, 0.0000,\n","         0.0000],\n","        [0.0000, 0.4431, 0.9882, 0.9882, 0.9882, 0.9451, 0.3294, 0.0039, 0.0000,\n","         0.0000],\n","        [0.0745, 0.8471, 0.9882, 0.9882, 0.9882, 0.4235, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.4118, 0.9882, 0.9882, 0.9882, 0.8118, 0.1176, 0.0000, 0.0000, 0.0000,\n","         0.0000],\n","        [0.4157, 0.9922, 0.9922, 0.9922, 0.4588, 0.0000, 0.0000, 0.0000, 0.0000,\n","         0.0000]])"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["Currently, our labels takes on the values between 0 and 9.\n","\n","Once again, the neural network can't simply predict an integer label for us. Whenever we have multiple labels, one approach we can take is to represent them as one-hot encoding.Here's how it works.\n","\n","**One-hot encoding**\n","\n","Suppose I have three labels (car, truck, motorcycles). One hot encoding represents each of the label with a list of numbers (or vectors) as follows:\n","\n","1. Assign a number/index to each label. For example - Car:0, Truck:1, Motorcycles:2\n","2. Then each label is represented as vector with the size of maximum number of possible labels (i.e. 3 in this case).\n","3. To represent each label, I store 1 in the appropriate location of the vector that this label is assigned to and zero in all other positions. So this is a vector representing a car `[1, 0, 0]`\n","\n","Subsequently, truck and motorcyles are `[0, 1, 0]` and `[0, 0, 1]`."],"metadata":{"id":"tmX1Reho-jq4"}},{"cell_type":"code","source":["ys_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AyRlvIex-N7n","executionInfo":{"status":"ok","timestamp":1706054426181,"user_tz":480,"elapsed":163,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"7bfb782d-714d-4d1f-856f-20c66a383d41"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0, 0, 0,  ..., 9, 9, 9])"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["There is a function in PyTorch called `one_hot` that does it for us.\n","\n","Below you will see it looks like for the first and last few rows (digit 0 and 9)"],"metadata":{"id":"8DGytkKgJm36"}},{"cell_type":"code","source":["import torch.nn.functional as F"],"metadata":{"id":"Z4CQP5cfJHES","executionInfo":{"status":"ok","timestamp":1706054450647,"user_tz":480,"elapsed":198,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["ys_train_enc = F.one_hot(ys_train, num_classes=10)\n","ys_train_enc.shape, ys_train_enc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVGkHm_a-dUE","executionInfo":{"status":"ok","timestamp":1706054451467,"user_tz":480,"elapsed":3,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"197abdb9-a192-426a-d50b-842eb214c2be"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([60000, 10]),\n"," tensor([[1, 0, 0,  ..., 0, 0, 0],\n","         [1, 0, 0,  ..., 0, 0, 0],\n","         [1, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 1],\n","         [0, 0, 0,  ..., 0, 0, 1],\n","         [0, 0, 0,  ..., 0, 0, 1]]))"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["ys_test_enc = F.one_hot(ys_test, num_classes=10)\n","ys_test_enc.shape, ys_test_enc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5SIKmn04akLB","executionInfo":{"status":"ok","timestamp":1706054457447,"user_tz":480,"elapsed":183,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"a5501fb3-cd09-404c-b61f-ee799f3469a8"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([10000, 10]),\n"," tensor([[1, 0, 0,  ..., 0, 0, 0],\n","         [1, 0, 0,  ..., 0, 0, 0],\n","         [1, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 1],\n","         [0, 0, 0,  ..., 0, 0, 1],\n","         [0, 0, 0,  ..., 0, 0, 1]]))"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["Finally, when passing our training images to the network, we can't pass 28x28 pixels as a matrix instead we have to flatten the matrix into a vector. We can do that using `view` method on the tensor"],"metadata":{"id":"GGuEFAAAb8Fh"}},{"cell_type":"code","source":["input_size = 28*28\n","xs_train = xs_train.view(-1, input_size)\n","xs_test = xs_test.view(-1, input_size)"],"metadata":{"id":"op2xcdbXb5ct","executionInfo":{"status":"ok","timestamp":1706054474774,"user_tz":480,"elapsed":184,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["xs_train.shape, xs_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BI3E8DTNdBT8","executionInfo":{"status":"ok","timestamp":1706054475838,"user_tz":480,"elapsed":148,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"a98c52f1-050c-45b3-cf45-097e7876f253"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([60000, 784]), torch.Size([10000, 784]))"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","source":["In order to pass images in batches, we will make use of the `DataLoader` class from PyTorch, which expects a dataset in the form of tuples (x, y). We can use zip function to get it."],"metadata":{"id":"3YTD6PtJaH8t"}},{"cell_type":"code","source":["train_dataset, test_dataset = list(zip(xs_train, ys_train_enc)), list(zip(xs_test, ys_test_enc))"],"metadata":{"id":"0w_Ht2rha0cV","executionInfo":{"status":"ok","timestamp":1706054498232,"user_tz":480,"elapsed":625,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["Each sample going into the neural network is a tensor with 784 values and the labels are now 10-dimensional vector."],"metadata":{"id":"VuZEAc3ixiI8"}},{"cell_type":"code","source":["x, y = train_dataset[0]\n","x.shape, y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vWP7mSBSbJUt","executionInfo":{"status":"ok","timestamp":1706054500012,"user_tz":480,"elapsed":4,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"9ebb757e-0c0f-42cb-8590-38dac4f9adc0"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([784]), tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["Defining the DataLoader to draw one batch of input images at a time. This will allow us to pass 120 images to the neural network in one training iteration."],"metadata":{"id":"9FShsbH_dohP"}},{"cell_type":"code","source":["train_dl = DataLoader(train_dataset, batch_size=120)\n","test_dl = DataLoader(test_dataset, batch_size=120)"],"metadata":{"id":"J6xd8e-0dmpJ","executionInfo":{"status":"ok","timestamp":1706054586422,"user_tz":480,"elapsed":214,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["We can peek a the first batch."],"metadata":{"id":"1DCcFGvgd9L3"}},{"cell_type":"code","source":["xs_first, ys_first = first(train_dl)\n","xs_first.shape, ys_first.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0BGDQ2jHeER7","executionInfo":{"status":"ok","timestamp":1706054631708,"user_tz":480,"elapsed":193,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"7a32b9e2-d2c8-4142-add4-3edc369a36f4"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([120, 784]), torch.Size([120, 10]))"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["# Loss Function Formulation\n","\n","Before we can build a neural network, one thing we need is a way to provide feedback to our network.\n","\n","In other words, when we show an image, such as digit 0, to our network but our network predicts something else, we will need to provide a score that indicates whether it's doing good or bad. A function that does it is called a **loss function**.\n","\n","How can we construct such a function? Remember how we represented our labels as one-hot encoded vector.\n","\n","Going back to earlier [car, truck, and motorcycle] example, suppose we pass an image of car to our network but the neural network predicts a truck (each of the values in neural network predictions `nn_preds` can be interpreted as probability that the neural network thinks it belongs to a specific class):\n"],"metadata":{"id":"08zCL3snKrqh"}},{"cell_type":"code","source":["car_label = tensor([1, 0, 0])\n","nn_preds = tensor([0.2, 0.7, 0.1])"],"metadata":{"id":"kvYSRJ4yJh4V","executionInfo":{"status":"ok","timestamp":1706054675231,"user_tz":480,"elapsed":186,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["When we have multi-classification problem, we can compute the loss by taking the negative log of the predictions across all the classes and summing them up.\n","\n","This loss value should go down when the neural network gets better at predicting correctly."],"metadata":{"id":"QKpzJybKzSBT"}},{"cell_type":"code","source":["-(car_label * torch.log(nn_preds)).sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1zp4upFjNAsM","executionInfo":{"status":"ok","timestamp":1706055338263,"user_tz":480,"elapsed":176,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"113ef1c2-b54e-463e-9277-6b2baf9ff30c"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(1.6094)"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["Suppose our neural networks predicts the car with more confidence even though it's still getting it wrong (Probability of a car has increased from 0.2 to 0.4). Consequently, the loss went down from 1.6 to 0.9 indicating that this prediction is better!"],"metadata":{"id":"c_PgPCA4VgD3"}},{"cell_type":"code","source":["nn_preds = tensor([0.4, 0.5, 0.1])\n","-(car_label * torch.log(nn_preds)).sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RXMGgFDTOjAu","executionInfo":{"status":"ok","timestamp":1706055342749,"user_tz":480,"elapsed":167,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"632f4e81-dc26-4401-f8fb-625382def1dd"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.9163)"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","source":["If it gets it right, the loss should go down even further."],"metadata":{"id":"2fL9c_7JV-F0"}},{"cell_type":"code","source":["nn_preds = tensor([0.7, 0.1, 0.2])\n","-(car_label * torch.log(nn_preds)).sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pF-ezceyTZ5d","executionInfo":{"status":"ok","timestamp":1706055394864,"user_tz":480,"elapsed":211,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"53090310-f209-48a2-aaab-fb377aab3965"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.3567)"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","source":["Quite often, instead of sending in one image at a time, we often send a batch of images to neural network.\n","\n","In that case, we can take the loss to be an average of loss across the items in the batch."],"metadata":{"id":"ZBf-5KA7WH13"}},{"cell_type":"code","source":["car_labels = tensor([\n","    [1, 0, 0],\n","    [1, 0, 0],\n","    [1, 0, 0]\n","])\n","nn_predictions = tensor(\n","    [\n","     [0.2, 0.7, 0.1],\n","     [0.4, 0.5, 0.1],\n","     [0.7, 0.1, 0.2]\n","    ]\n",")\n","losses = -(car_labels * torch.log(nn_predictions)).sum(dim=1)\n","avg_loss = losses.sum() / car_labels.shape[0]\n","print(f\"Losses: {losses}, Average Loss: {avg_loss}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t5mXA2E6TkIQ","executionInfo":{"status":"ok","timestamp":1706055406316,"user_tz":480,"elapsed":164,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"e637f234-83d7-44d2-d022-4d7f36d5e9c4"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Losses: tensor([1.6094, 0.9163, 0.3567]), Average Loss: 0.9608011841773987\n"]}]},{"cell_type":"markdown","source":["Now we can define the cross-entropy loss in a function."],"metadata":{"id":"mzq70iCv08h8"}},{"cell_type":"code","source":["def cross_entropy_loss(true_labels, predictions, printLoss=False):\n","  losses = -(true_labels * torch.log(predictions+1e-15)).sum(dim=1)\n","  average_loss = losses.sum() / true_labels.shape[0]\n","  if printLoss: print(f\"Loss: {average_loss.item():.4f}\")\n","  return average_loss"],"metadata":{"id":"8B03wsHaULpY","executionInfo":{"status":"ok","timestamp":1706055442170,"user_tz":480,"elapsed":192,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["cross_entropy_loss(car_labels, nn_predictions, True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YJiWu04LYq25","executionInfo":{"status":"ok","timestamp":1706055447186,"user_tz":480,"elapsed":191,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"e8fefacd-1f26-49c1-8924-379eab0868ee"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Loss: 0.9608\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(0.9608)"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","source":["# Constructing the Neural Network\n","\n","To begin with, I will create a neural network with one layer."],"metadata":{"id":"ABjz9kMVeUCB"}},{"cell_type":"markdown","source":["## Initialize the parameters randomly"],"metadata":{"id":"bFKhCLdoe9hB"}},{"cell_type":"code","source":["def init_params(size, std=1.0):\n","  return (torch.randn(size)*std).requires_grad_()"],"metadata":{"id":"45RzRim0Y4tv","executionInfo":{"status":"ok","timestamp":1706055541020,"user_tz":480,"elapsed":177,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":["Now we have our weights & biases."],"metadata":{"id":"vNOH822Y1gVj"}},{"cell_type":"code","source":["weights = init_params((input_size, 10))\n","biases = init_params(10)"],"metadata":{"id":"6P7tQJYGfQHY","executionInfo":{"status":"ok","timestamp":1706055594617,"user_tz":480,"elapsed":167,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["weights.shape, biases.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fdNfCTaJ1nzV","executionInfo":{"status":"ok","timestamp":1706055603560,"user_tz":480,"elapsed":4,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"9418204c-4eb8-4284-f541-ff35b0c16857"},"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([784, 10]), torch.Size([10]))"]},"metadata":{},"execution_count":47}]},{"cell_type":"markdown","source":["The shape of each incoming batch will have the following shape: `[batch_size, input_size]`."],"metadata":{"id":"86QMfPaR1xuo"}},{"cell_type":"code","source":["xs_first.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m1c1azCO16g-","executionInfo":{"status":"ok","timestamp":1706055680159,"user_tz":480,"elapsed":175,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"2a293d12-5617-45d6-aba9-d4be32f79d9d"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([120, 784])"]},"metadata":{},"execution_count":48}]},{"cell_type":"markdown","source":["## Get the predictions\n","\n","We can get the predictions by performing matrix multiplication of the input & the weights and adding biases to it."],"metadata":{"id":"kmKU4E7AgFvS"}},{"cell_type":"code","source":["def linear(xb): return xb@weights + biases"],"metadata":{"id":"vg_0Dgu1fmvI","executionInfo":{"status":"ok","timestamp":1706055796945,"user_tz":480,"elapsed":225,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["preds = linear(xs_first)\n","preds.shape, preds[:1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h-VwNBEGfr4F","executionInfo":{"status":"ok","timestamp":1706055819578,"user_tz":480,"elapsed":175,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"be3da212-2de1-4ffb-ad1b-1cdd2eb1d011"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([120, 10]),\n"," tensor([[  7.6349,   4.5616,  24.0088,  16.5575,  -3.5533,   0.5458,  13.9238,\n","           -2.8771, -14.8012,  -2.2896]], grad_fn=<SliceBackward0>))"]},"metadata":{},"execution_count":52}]},{"cell_type":"markdown","source":["The predictions that we get aren't quite the probabilities like we expected and we need probabilities a vector of probabilities to pass into our loss function.\n","\n","Let's see how we can achieve it. First let's take the exponent of our vector."],"metadata":{"id":"IK_t9bXcivQh"}},{"cell_type":"code","source":["preds_exp = torch.exp(preds)\n","preds_exp.shape, preds_exp[:1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C4xulKKHgPVO","executionInfo":{"status":"ok","timestamp":1706055865229,"user_tz":480,"elapsed":203,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"1fbc2d8b-7091-4641-896d-d0fb028634eb"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([120, 10]),\n"," tensor([[2.0691e+03, 9.5736e+01, 2.6723e+10, 1.5518e+07, 2.8631e-02, 1.7259e+00,\n","          1.1144e+06, 5.6297e-02, 3.7317e-07, 1.0130e-01]],\n","        grad_fn=<SliceBackward0>))"]},"metadata":{},"execution_count":53}]},{"cell_type":"markdown","source":["Second, we sum up all the elements in the vector after taking the exponent."],"metadata":{"id":"HE-qvPDs2wZw"}},{"cell_type":"code","source":["total_ = preds_exp.sum(dim=1)\n","total_.shape, total_[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dqDs-PQpkTwD","executionInfo":{"status":"ok","timestamp":1705715561058,"user_tz":480,"elapsed":459,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"3e1db159-c52c-41c4-a96a-9d4acb50dfc5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([120]), tensor(1054781.5000, grad_fn=<SelectBackward0>))"]},"metadata":{},"execution_count":166}]},{"cell_type":"markdown","source":["Third, we divide the exponent of our vector by the sum we just computed.\n","\n","However, the issue is the sum has one fewer dimension and it won't be able to broadcast if we want to divide. Therefore, we will specify `keepdims=True` when performing the sum. Let's see the resulting shape."],"metadata":{"id":"owr0qK8L3CMl"}},{"cell_type":"code","source":["total_ = preds_exp.sum(dim=1, keepdims=True)\n","total_.shape, total_[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mHVi4Kk1kk4u","executionInfo":{"status":"ok","timestamp":1706056092602,"user_tz":480,"elapsed":170,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"c533c396-c333-4125-cc95-973764d1b795"},"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([120, 1]), tensor([2.6740e+10], grad_fn=<SelectBackward0>))"]},"metadata":{},"execution_count":54}]},{"cell_type":"markdown","source":["Great! Now, we can perform element-wise division correctly (via broadcasting)."],"metadata":{"id":"JY8CD9pG3ind"}},{"cell_type":"code","source":["probs = preds_exp / preds_exp.sum(dim=1, keepdims=True)\n","probs.shape, probs[0, :], probs[0, :].sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yaUYWNO8gpma","executionInfo":{"status":"ok","timestamp":1706056136905,"user_tz":480,"elapsed":180,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"48cf00a7-ef1e-41d4-818a-db8372e313a7"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([120, 10]),\n"," tensor([7.7378e-08, 3.5803e-09, 9.9938e-01, 5.8035e-04, 1.0707e-12, 6.4544e-11,\n","         4.1674e-05, 2.1053e-12, 1.3956e-17, 3.7885e-12],\n","        grad_fn=<SliceBackward0>),\n"," tensor(1.0000, grad_fn=<SumBackward0>))"]},"metadata":{},"execution_count":55}]},{"cell_type":"markdown","source":["Since there are 120 images in each batch, the sum of the probabilities is 120. So, we know that we have correctly computed the probabilities."],"metadata":{"id":"OnIa4yeV3uJp"}},{"cell_type":"code","source":["probs.sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w6bphPqRjji5","executionInfo":{"status":"ok","timestamp":1706056143302,"user_tz":480,"elapsed":201,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"141ba284-f66a-4167-98e5-b4e5ec637af7"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(120., grad_fn=<SumBackward0>)"]},"metadata":{},"execution_count":56}]},{"cell_type":"markdown","source":["Taking the exponent of the numerical output of the neural network and dividing it by its sum is called the **softmax** function. Let's put this in a function."],"metadata":{"id":"NkAQr5vQl6Og"}},{"cell_type":"code","source":["def softmax(x):\n","  exponential = torch.exp(x)\n","  summation_classes = exponential.sum(dim=1, keepdims=True)\n","  return exponential / summation_classes"],"metadata":{"id":"cpszNIuolO9t","executionInfo":{"status":"ok","timestamp":1706056287123,"user_tz":480,"elapsed":191,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":["Now that our neural network is predicting probabilities, we can find the loss."],"metadata":{"id":"tL7MdHXO4Vk4"}},{"cell_type":"code","source":["loss = cross_entropy_loss(true_labels=ys_first, predictions=probs, printLoss=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SF74Wneqmwff","executionInfo":{"status":"ok","timestamp":1706056294432,"user_tz":480,"elapsed":130,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"a06cb414-dc0c-46a8-aa1a-abc0e6252999"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Loss: 7.5432\n"]}]},{"cell_type":"markdown","source":["## Compute the gradients and perform back-propogation."],"metadata":{"id":"VxUG7w_F4h-X"}},{"cell_type":"markdown","source":["By calling `backward` on our loss functions, PyTorch will compute the gradients for all the parameters."],"metadata":{"id":"POlcIUFa4oL3"}},{"cell_type":"code","source":["loss.backward()"],"metadata":{"id":"AyvG94YIncFe","executionInfo":{"status":"ok","timestamp":1706056296716,"user_tz":480,"elapsed":158,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":["These gradients will be accessible in `grad` attribute of the parameters."],"metadata":{"id":"_6k0QAns41HW"}},{"cell_type":"code","source":["weights.grad.shape, weights.grad.mean(), biases.grad"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JrV3qOz0nftm","executionInfo":{"status":"ok","timestamp":1706056461636,"user_tz":480,"elapsed":255,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"161e6e7a-9df4-4ae7-dd26-267e5dc6a9c5"},"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([784, 10]),\n"," tensor(6.0821e-10),\n"," tensor([-9.4333e-01,  1.2496e-01,  3.8489e-01,  2.0558e-01,  1.5233e-02,\n","          9.1414e-03,  1.6477e-01,  7.5494e-03,  2.7125e-05,  3.1173e-02]))"]},"metadata":{},"execution_count":60}]},{"cell_type":"markdown","source":["Now we can put this step into a function."],"metadata":{"id":"cKov4lhh5GVw"}},{"cell_type":"code","source":["def find_gradient(xb, yb, model):\n","  predictions = model(xb)\n","  probabilities = softmax(predictions)\n","  loss = cross_entropy_loss(yb, probabilities)\n","  loss.backward()"],"metadata":{"id":"YX2dsLOFnlyq","executionInfo":{"status":"ok","timestamp":1706056520341,"user_tz":480,"elapsed":183,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":["If we call this fucntion a couple of times, you will notice that the gradient starts accumulating."],"metadata":{"id":"qOqAn8fp5LdT"}},{"cell_type":"code","source":["find_gradient(xs_first, ys_first, linear)\n","weights.grad.mean(), biases.grad"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ajrqUSBFoO98","executionInfo":{"status":"ok","timestamp":1706056552618,"user_tz":480,"elapsed":176,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"e8e45cfa-889d-44f4-f71a-b0e2d443f661"},"execution_count":62,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(1.2164e-09),\n"," tensor([-1.8867e+00,  2.4993e-01,  7.6977e-01,  4.1116e-01,  3.0465e-02,\n","          1.8283e-02,  3.2954e-01,  1.5099e-02,  5.4249e-05,  6.2346e-02]))"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["find_gradient(xs_first, ys_first, linear)\n","weights.grad.mean(), biases.grad"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mjjRDgHQoZt_","executionInfo":{"status":"ok","timestamp":1706056553866,"user_tz":480,"elapsed":177,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"c6680d4b-327a-43d2-d203-37faa4ce134a"},"execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(1.4597e-09),\n"," tensor([-2.8300e+00,  3.7489e-01,  1.1547e+00,  6.1674e-01,  4.5698e-02,\n","          2.7424e-02,  4.9432e-01,  2.2648e-02,  8.1374e-05,  9.3519e-02]))"]},"metadata":{},"execution_count":63}]},{"cell_type":"markdown","source":["However, that's not the desirable behavior in neural network training. Once we have adjusted the weights in one training iteration, we want to reset it zero.\n","\n","We can achieve this by calling `.zero` on our grad attribute."],"metadata":{"id":"WXMFNYhC5T7-"}},{"cell_type":"code","source":["weights.grad.zero_()\n","biases.grad.zero_();"],"metadata":{"id":"0baEpqvrogIz","executionInfo":{"status":"ok","timestamp":1706056659878,"user_tz":480,"elapsed":183,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":["We can put all the training steps of one iteration into a function."],"metadata":{"id":"_IFDroSt5y1f"}},{"cell_type":"code","source":["def train_epoch(model, learning_rate, parameters):\n","  for xb, yb in train_dl:\n","    find_gradient(xb, yb, model)\n","    for p in parameters:\n","      p.data -= p.grad * learning_rate\n","      p.grad.zero_()"],"metadata":{"id":"keWOCOAfpE9L","executionInfo":{"status":"ok","timestamp":1706056736266,"user_tz":480,"elapsed":202,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":["During the trianing, besides the loss, we also care about other metrics.\n","\n","For example, we might want to know the accuracy of our classifier.\n","\n","Let's try to write the code to find the accuracy with sample labels and predictions as follow:\n","\n","1. Get the index of the maximum value in our predictions and true labels.\n","2. If these two indexes are same, then it's correct. Otherwise, it's wrong.\n","\n","Since we are dealing with multiple items (or images) at a time, we can get the accuracy for the entire batch by taking the mean."],"metadata":{"id":"YxtSesTp6FTs"}},{"cell_type":"code","source":["car_labels = tensor([\n","    [1, 0, 0],\n","    [1, 0, 0],\n","    [1, 0, 0]\n","])\n","nn_predictions = tensor(\n","    [\n","     [0.2, 0.7, 0.1],\n","     [0.4, 0.5, 0.1],\n","     [0.7, 0.1, 0.2]\n","    ]\n",")\n","\n","_, predicted_labels = torch.max(nn_predictions, 1)\n","print(f\"Predicted: {predicted_labels}\")\n","_, true_car_labels = torch.max(car_labels, 1)\n","print(f\"True: {true_car_labels}\")\n","(predicted_labels == true_car_labels).float().mean()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x63n8OTWomP8","executionInfo":{"status":"ok","timestamp":1706056978325,"user_tz":480,"elapsed":224,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"002c8c2b-cd62-4216-f5c9-58760c8e42ce"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted: tensor([1, 1, 0])\n","True: tensor([0, 0, 0])\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(0.3333)"]},"metadata":{},"execution_count":67}]},{"cell_type":"markdown","source":["Now we can put it into a function to compute the accuracy for each batch."],"metadata":{"id":"pK_-AbF567Sx"}},{"cell_type":"code","source":["def batch_accuracy(predictions_batch, labels_batch):\n","  _, predicted_labels = torch.max(predictions_batch, 1)\n","  _, true_labels = torch.max(labels_batch, 1)\n","  return (predicted_labels == true_labels).float().mean()"],"metadata":{"id":"G3sibzICuQw7","executionInfo":{"status":"ok","timestamp":1706057028879,"user_tz":480,"elapsed":191,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":["Testing on dummy dataset."],"metadata":{"id":"c7yeiQ0O7NIZ"}},{"cell_type":"code","source":["batch_accuracy(nn_predictions, car_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5H8pcD_6wT4c","executionInfo":{"status":"ok","timestamp":1706057043825,"user_tz":480,"elapsed":183,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"93fdc1b4-5496-496f-b7c8-8daa61ae4df8"},"execution_count":69,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.3333)"]},"metadata":{},"execution_count":69}]},{"cell_type":"markdown","source":["In each iteration of the training, we would like to compute the accuracy on the test set."],"metadata":{"id":"EkfVat8z7PPQ"}},{"cell_type":"code","source":["def validate_epoch(model):\n","  accs = []\n","  for xb, yb in test_dl:\n","    accs.append(batch_accuracy(model(xb), yb))\n","  return round(torch.stack(accs).mean().item() , 4)"],"metadata":{"id":"djSdKtF8wahW","executionInfo":{"status":"ok","timestamp":1706057129109,"user_tz":480,"elapsed":205,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["validate_epoch(linear)"],"metadata":{"id":"7CSwvQJ5w4cf","executionInfo":{"status":"ok","timestamp":1706057131503,"user_tz":480,"elapsed":188,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"d212b7f0-c88c-4adb-f65d-2aa6d0059744","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.1443"]},"metadata":{},"execution_count":71}]},{"cell_type":"markdown","source":["## Train until a stopping criterion is reached.\n","\n","We can now train the whole thing from the scratch until a criterion we specify is reached.For now, I can train for 25 iterations."],"metadata":{"id":"q1nCjEld7sD6"}},{"cell_type":"code","source":["lr = 1\n","weights = init_params((input_size, 10))\n","biases = init_params(10)\n","params = weights, biases\n","for i in range(25):\n","  train_epoch(linear, 0.1, params)\n","  print(validate_epoch(linear), end=\" \")"],"metadata":{"id":"6xx7LAjHw8ft","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706057578047,"user_tz":480,"elapsed":14847,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"9c666255-8cf3-40e4-9304-e99d39cd4806"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["0.1399 0.23 0.3362 0.4051 0.4504 0.4823 0.506 0.523 0.5386 0.5509 0.5593 0.566 0.5752 0.5814 0.5874 0.5928 0.5968 0.6013 0.6053 0.6076 0.6104 0.6126 0.6141 0.6164 0.6192 "]}]},{"cell_type":"markdown","source":["We achieved an validation accuracy of 61%. There is one serious limiting factor on our network.\n","\n","Currently, our neural network is only able to learn linear function. So how do we fix that? We will fix it by adding a non-linear function to the output of the linear model (in particular a function called ReLU)."],"metadata":{"id":"RZr33XC_9fHz"}},{"cell_type":"markdown","source":["## Non-Linearity\n","\n","PyTorch has built-in ReLU funtion.\n","\n","All it does is return zero when the input is negative. Otherwise, it returns the input itself."],"metadata":{"id":"8FxxuEKT-Gez"}},{"cell_type":"code","source":["import torch.nn.functional as F\n","F.relu(tensor([-3, 1, 4]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KmTxAzLE82Wi","executionInfo":{"status":"ok","timestamp":1706058015609,"user_tz":480,"elapsed":207,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"9022183e-bfb1-4e58-fcfa-3753fb1290a2"},"execution_count":76,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0, 1, 4])"]},"metadata":{},"execution_count":76}]},{"cell_type":"markdown","source":["Once we did the matrix multiplication, all we need to do it pass it through the ReLU function.\n","\n","We pass the linear output of the first batch into ReLU."],"metadata":{"id":"YW2uXIW-_DKS"}},{"cell_type":"code","source":["F.relu(linear(xs_first))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zWDInEyo-ysn","executionInfo":{"status":"ok","timestamp":1706058147093,"user_tz":480,"elapsed":198,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"d205a5f7-2599-4f38-940c-03e31900d81d"},"execution_count":79,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[32.4036,  0.0000, 12.6207,  ...,  0.0000, 21.2366,  3.4717],\n","        [25.3043,  0.0000,  1.8662,  ..., 10.2617,  8.3608,  7.2364],\n","        [19.2242,  0.0000,  2.9971,  ...,  0.0000, 12.4211, 16.1132],\n","        ...,\n","        [18.5834,  0.0000,  2.5219,  ...,  0.0000, 10.2877,  7.6897],\n","        [26.3569,  0.0000, 13.6052,  ...,  0.0000, 18.3796,  0.0000],\n","        [ 7.7505,  0.0000,  1.3770,  ...,  7.1471,  4.7673,  0.0000]],\n","       grad_fn=<ReluBackward0>)"]},"metadata":{},"execution_count":79}]},{"cell_type":"markdown","source":["Let's define our neural network again to include the ReLU as well."],"metadata":{"id":"pyR6N9Pk_lKg"}},{"cell_type":"code","source":["def neural_net(xb):\n","  res = linear(xb)\n","  return F.relu(res)"],"metadata":{"id":"a7n_TIvO-9WC","executionInfo":{"status":"ok","timestamp":1706058276332,"user_tz":480,"elapsed":158,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":80,"outputs":[]},{"cell_type":"markdown","source":["Now we will try the training again for 25 iterations with this."],"metadata":{"id":"ayMUxICd_4Wa"}},{"cell_type":"code","source":["lr = 1\n","weights = init_params((input_size, 10))\n","biases = init_params(10)\n","params = weights, biases\n","for i in range(25):\n","  train_epoch(neural_net, 0.1, params)\n","  print(validate_epoch(neural_net), end=\" \")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WVQugsE-_1vf","executionInfo":{"status":"ok","timestamp":1706058424705,"user_tz":480,"elapsed":14567,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"6f9d9d60-6603-47f7-89b4-9960d7c297f4"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["0.2364 0.2571 0.3437 0.4529 0.524 0.5639 0.5917 0.6135 0.6297 0.6412 0.6506 0.659 0.6664 0.6726 0.6792 0.683 0.686 0.6906 0.6953 0.6979 0.7008 0.7041 0.7075 0.7092 0.7106 "]}]},{"cell_type":"markdown","source":["An accuracy of 71%! Clearly, our neural network is more powerful now compared to the linear model before and maybe if we train for longer we can even achieve better performance."],"metadata":{"id":"_FnluIn1AcEt"}},{"cell_type":"markdown","source":["# Deep Neural Network\n","\n","Now that we have written all the components to train one layer neural network, let's try to put everything together again and extend our code for handling multiple layers so we can build deep neural network."],"metadata":{"id":"0cuznCFZA7Wq"}},{"cell_type":"markdown","source":["While we had one matrix to store the parameters of a layer, we will now need to have mutiple matrices to represent multiple layers.\n","\n","I will rewrite the function to initialize parameters from earlier. This function will:\n","\n","1. Take a list of number of units that the user wants at each layer (The input layer should have 784 units and the final layer should have 10 units since there are 10 classes while the hidden units can be arbitary).\n","2. Initialize the weights & biases as before for each layers (I have used some heuristic for weight initializtion that works better - all it does it scale the weights a little better).\n","3. Tells PyTorch that these parameters will be required for gradient computation later on."],"metadata":{"id":"Me9PBCLSBzxh"}},{"cell_type":"code","source":["def init_params(sizes: list):\n","  n = len(sizes) # Number of layers as length of the sizes\n","  weights = [(torch.rand(sizes[i], sizes[i+1])-0.3) / sizes[i+1]*4 for i in range(n-1)]\n","  biases = [torch.rand(sizes[i+1])*0.1 for i in range(n-1)]\n","  for params in weights+biases: params.requires_grad_()\n","  return weights, biases"],"metadata":{"id":"puMWS2j0AWdQ","executionInfo":{"status":"ok","timestamp":1706065799159,"user_tz":480,"elapsed":209,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":199,"outputs":[]},{"cell_type":"markdown","source":["Let's double-check its correct."],"metadata":{"id":"lvFEnyUbGeeG"}},{"cell_type":"code","source":["w, b = init_params([4, 2, 2, 1])\n","for a, b in zip(w, b):\n","  print(a.shape, b.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rybRd_JSF602","executionInfo":{"status":"ok","timestamp":1706063727304,"user_tz":480,"elapsed":248,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"b2fbc1f5-0991-449e-d1d7-d1d47e166cd9"},"execution_count":138,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 2]) torch.Size([2])\n","torch.Size([2, 2]) torch.Size([2])\n","torch.Size([2, 1]) torch.Size([1])\n"]}]},{"cell_type":"markdown","source":["Once we have parameters initialized, we will write a function to do the forward pass (i.e. send the images through the whole network and get the prediction.) through the model.\n","\n","Similar to earlier, we will receive input of shape `[batch_size, input_size]`."],"metadata":{"id":"sBP4j6v6G49A"}},{"cell_type":"code","source":["def neural_network(input_batch, params):\n","  weights, biases = params\n","  n = len(weights) # Find out the number of layers\n","  output = input_batch\n","  for i, (layer_weights, layer_biases) in enumerate(zip(weights, biases)):\n","    output = output @ layer_weights + layer_biases\n","    if i != n-1: output = F.relu(output)\n","  return softmax(output)"],"metadata":{"id":"9CN6ZhjXGVNq","executionInfo":{"status":"ok","timestamp":1706064949405,"user_tz":480,"elapsed":318,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":169,"outputs":[]},{"cell_type":"markdown","source":["Next, I will write one more function that computes the gradients and perform back-propogation by updating the gradients."],"metadata":{"id":"AVNNEnaNJltV"}},{"cell_type":"code","source":["def backprop(true_labels, predictions, lr, params):\n","  # Compute the loss\n","  loss = cross_entropy_loss(true_labels, predictions)\n","  loss.backward()\n","  with torch.no_grad():\n","    weights, biases = params\n","    for layer_params in weights+biases:\n","      layer_params.sub_(layer_params.grad * lr)\n","      layer_params.grad.zero_()"],"metadata":{"id":"xsFVpT-jI4-8","executionInfo":{"status":"ok","timestamp":1706064673430,"user_tz":480,"elapsed":238,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":159,"outputs":[]},{"cell_type":"markdown","source":["Now we write a function to train one epoch as before."],"metadata":{"id":"j57J_T-uNdPh"}},{"cell_type":"code","source":["def train_epoch(model, learning_rate, params):\n","  for xs, ys in train_dl:\n","    predictions = model(xs, params)\n","    backprop(ys, predictions, learning_rate, params)"],"metadata":{"id":"vTEV89JbMjn3","executionInfo":{"status":"ok","timestamp":1706064675901,"user_tz":480,"elapsed":238,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":160,"outputs":[]},{"cell_type":"markdown","source":["Modify the validate epoch function from earlier to take `params` as input."],"metadata":{"id":"DjQlW73JeAPy"}},{"cell_type":"code","source":["def validate_epoch(model, params):\n","  accs = []\n","  for xb, yb in test_dl:\n","    accs.append(batch_accuracy(model(xb, params), yb))\n","  return round(torch.stack(accs).mean().item() , 4)"],"metadata":{"id":"0tVT0ndATTpV","executionInfo":{"status":"ok","timestamp":1706064677454,"user_tz":480,"elapsed":214,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}}},"execution_count":161,"outputs":[]},{"cell_type":"markdown","source":["Let's start training our deep neural network with hidden layers."],"metadata":{"id":"Q3jvK1epPPyc"}},{"cell_type":"code","source":["lr = 0.1\n","epochs = 200\n","parameters = init_params([input_size, 100, 10])\n","for i in range(epochs):\n","  train_epoch(neural_network, lr, parameters)\n","  print(f\" Iteration {i} , Validation Accuracy: {validate_epoch(neural_network, parameters)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ckP4RDNmO4KK","executionInfo":{"status":"ok","timestamp":1706066633099,"user_tz":480,"elapsed":156443,"user":{"displayName":"Kyaw Htet Win","userId":"07452281808661990081"}},"outputId":"aad832cf-f63b-41b6-d121-fb57cac68ceb"},"execution_count":207,"outputs":[{"output_type":"stream","name":"stdout","text":[" Iteration 0 , Validation Accuracy: 0.108\n"," Iteration 1 , Validation Accuracy: 0.1198\n"," Iteration 2 , Validation Accuracy: 0.1453\n"," Iteration 3 , Validation Accuracy: 0.1829\n"," Iteration 4 , Validation Accuracy: 0.233\n"," Iteration 5 , Validation Accuracy: 0.2729\n"," Iteration 6 , Validation Accuracy: 0.2919\n"," Iteration 7 , Validation Accuracy: 0.2988\n"," Iteration 8 , Validation Accuracy: 0.2895\n"," Iteration 9 , Validation Accuracy: 0.3142\n"," Iteration 10 , Validation Accuracy: 0.327\n"," Iteration 11 , Validation Accuracy: 0.3123\n"," Iteration 12 , Validation Accuracy: 0.3064\n"," Iteration 13 , Validation Accuracy: 0.3113\n"," Iteration 14 , Validation Accuracy: 0.315\n"," Iteration 15 , Validation Accuracy: 0.3487\n"," Iteration 16 , Validation Accuracy: 0.393\n"," Iteration 17 , Validation Accuracy: 0.3971\n"," Iteration 18 , Validation Accuracy: 0.3817\n"," Iteration 19 , Validation Accuracy: 0.3637\n"," Iteration 20 , Validation Accuracy: 0.3815\n"," Iteration 21 , Validation Accuracy: 0.4098\n"," Iteration 22 , Validation Accuracy: 0.4296\n"," Iteration 23 , Validation Accuracy: 0.4506\n"," Iteration 24 , Validation Accuracy: 0.4607\n"," Iteration 25 , Validation Accuracy: 0.4578\n"," Iteration 26 , Validation Accuracy: 0.4726\n"," Iteration 27 , Validation Accuracy: 0.4664\n"," Iteration 28 , Validation Accuracy: 0.4791\n"," Iteration 29 , Validation Accuracy: 0.5016\n"," Iteration 30 , Validation Accuracy: 0.5456\n"," Iteration 31 , Validation Accuracy: 0.5627\n"," Iteration 32 , Validation Accuracy: 0.5635\n"," Iteration 33 , Validation Accuracy: 0.562\n"," Iteration 34 , Validation Accuracy: 0.5647\n"," Iteration 35 , Validation Accuracy: 0.5687\n"," Iteration 36 , Validation Accuracy: 0.5738\n"," Iteration 37 , Validation Accuracy: 0.5898\n"," Iteration 38 , Validation Accuracy: 0.6091\n"," Iteration 39 , Validation Accuracy: 0.6242\n"," Iteration 40 , Validation Accuracy: 0.6302\n"," Iteration 41 , Validation Accuracy: 0.6282\n"," Iteration 42 , Validation Accuracy: 0.6295\n"," Iteration 43 , Validation Accuracy: 0.6329\n"," Iteration 44 , Validation Accuracy: 0.6392\n"," Iteration 45 , Validation Accuracy: 0.6453\n"," Iteration 46 , Validation Accuracy: 0.6479\n"," Iteration 47 , Validation Accuracy: 0.6502\n"," Iteration 48 , Validation Accuracy: 0.6588\n"," Iteration 49 , Validation Accuracy: 0.664\n"," Iteration 50 , Validation Accuracy: 0.6713\n"," Iteration 51 , Validation Accuracy: 0.6776\n"," Iteration 52 , Validation Accuracy: 0.6837\n"," Iteration 53 , Validation Accuracy: 0.689\n"," Iteration 54 , Validation Accuracy: 0.6944\n"," Iteration 55 , Validation Accuracy: 0.701\n"," Iteration 56 , Validation Accuracy: 0.7046\n"," Iteration 57 , Validation Accuracy: 0.7089\n"," Iteration 58 , Validation Accuracy: 0.7149\n"," Iteration 59 , Validation Accuracy: 0.7195\n"," Iteration 60 , Validation Accuracy: 0.7254\n"," Iteration 61 , Validation Accuracy: 0.7304\n"," Iteration 62 , Validation Accuracy: 0.7369\n"," Iteration 63 , Validation Accuracy: 0.7408\n"," Iteration 64 , Validation Accuracy: 0.7435\n"," Iteration 65 , Validation Accuracy: 0.7478\n"," Iteration 66 , Validation Accuracy: 0.7526\n"," Iteration 67 , Validation Accuracy: 0.7565\n"," Iteration 68 , Validation Accuracy: 0.7588\n"," Iteration 69 , Validation Accuracy: 0.7619\n"," Iteration 70 , Validation Accuracy: 0.7624\n"," Iteration 71 , Validation Accuracy: 0.7641\n"," Iteration 72 , Validation Accuracy: 0.7608\n"," Iteration 73 , Validation Accuracy: 0.7605\n"," Iteration 74 , Validation Accuracy: 0.7576\n"," Iteration 75 , Validation Accuracy: 0.759\n"," Iteration 76 , Validation Accuracy: 0.7593\n"," Iteration 77 , Validation Accuracy: 0.7618\n"," Iteration 78 , Validation Accuracy: 0.7642\n"," Iteration 79 , Validation Accuracy: 0.7661\n"," Iteration 80 , Validation Accuracy: 0.7679\n"," Iteration 81 , Validation Accuracy: 0.7713\n"," Iteration 82 , Validation Accuracy: 0.7731\n"," Iteration 83 , Validation Accuracy: 0.7761\n"," Iteration 84 , Validation Accuracy: 0.7794\n"," Iteration 85 , Validation Accuracy: 0.7834\n"," Iteration 86 , Validation Accuracy: 0.7871\n"," Iteration 87 , Validation Accuracy: 0.7898\n"," Iteration 88 , Validation Accuracy: 0.7946\n"," Iteration 89 , Validation Accuracy: 0.7998\n"," Iteration 90 , Validation Accuracy: 0.8031\n"," Iteration 91 , Validation Accuracy: 0.8055\n"," Iteration 92 , Validation Accuracy: 0.8099\n"," Iteration 93 , Validation Accuracy: 0.8137\n"," Iteration 94 , Validation Accuracy: 0.8171\n"," Iteration 95 , Validation Accuracy: 0.8204\n"," Iteration 96 , Validation Accuracy: 0.8249\n"," Iteration 97 , Validation Accuracy: 0.8289\n"," Iteration 98 , Validation Accuracy: 0.832\n"," Iteration 99 , Validation Accuracy: 0.8354\n"," Iteration 100 , Validation Accuracy: 0.8367\n"," Iteration 101 , Validation Accuracy: 0.8401\n"," Iteration 102 , Validation Accuracy: 0.8421\n"," Iteration 103 , Validation Accuracy: 0.8454\n"," Iteration 104 , Validation Accuracy: 0.8489\n"," Iteration 105 , Validation Accuracy: 0.8524\n"," Iteration 106 , Validation Accuracy: 0.8551\n"," Iteration 107 , Validation Accuracy: 0.858\n"," Iteration 108 , Validation Accuracy: 0.859\n"," Iteration 109 , Validation Accuracy: 0.8626\n"," Iteration 110 , Validation Accuracy: 0.8647\n"," Iteration 111 , Validation Accuracy: 0.8688\n"," Iteration 112 , Validation Accuracy: 0.8706\n"," Iteration 113 , Validation Accuracy: 0.8729\n"," Iteration 114 , Validation Accuracy: 0.8754\n"," Iteration 115 , Validation Accuracy: 0.8775\n"," Iteration 116 , Validation Accuracy: 0.8808\n"," Iteration 117 , Validation Accuracy: 0.8825\n"," Iteration 118 , Validation Accuracy: 0.8831\n"," Iteration 119 , Validation Accuracy: 0.885\n"," Iteration 120 , Validation Accuracy: 0.8865\n"," Iteration 121 , Validation Accuracy: 0.8881\n"," Iteration 122 , Validation Accuracy: 0.8905\n"," Iteration 123 , Validation Accuracy: 0.8918\n"," Iteration 124 , Validation Accuracy: 0.8927\n"," Iteration 125 , Validation Accuracy: 0.8944\n"," Iteration 126 , Validation Accuracy: 0.8954\n"," Iteration 127 , Validation Accuracy: 0.8972\n"," Iteration 128 , Validation Accuracy: 0.8983\n"," Iteration 129 , Validation Accuracy: 0.8995\n"," Iteration 130 , Validation Accuracy: 0.9006\n"," Iteration 131 , Validation Accuracy: 0.9018\n"," Iteration 132 , Validation Accuracy: 0.9029\n"," Iteration 133 , Validation Accuracy: 0.9041\n"," Iteration 134 , Validation Accuracy: 0.9059\n"," Iteration 135 , Validation Accuracy: 0.9085\n"," Iteration 136 , Validation Accuracy: 0.9097\n"," Iteration 137 , Validation Accuracy: 0.9105\n"," Iteration 138 , Validation Accuracy: 0.9116\n"," Iteration 139 , Validation Accuracy: 0.9123\n"," Iteration 140 , Validation Accuracy: 0.9132\n"," Iteration 141 , Validation Accuracy: 0.9144\n"," Iteration 142 , Validation Accuracy: 0.9146\n"," Iteration 143 , Validation Accuracy: 0.9156\n"," Iteration 144 , Validation Accuracy: 0.9164\n"," Iteration 145 , Validation Accuracy: 0.9177\n"," Iteration 146 , Validation Accuracy: 0.9191\n"," Iteration 147 , Validation Accuracy: 0.9195\n"," Iteration 148 , Validation Accuracy: 0.9201\n"," Iteration 149 , Validation Accuracy: 0.9214\n"," Iteration 150 , Validation Accuracy: 0.9221\n"," Iteration 151 , Validation Accuracy: 0.9229\n"," Iteration 152 , Validation Accuracy: 0.9236\n"," Iteration 153 , Validation Accuracy: 0.9236\n"," Iteration 154 , Validation Accuracy: 0.9244\n"," Iteration 155 , Validation Accuracy: 0.9253\n"," Iteration 156 , Validation Accuracy: 0.9261\n"," Iteration 157 , Validation Accuracy: 0.9263\n"," Iteration 158 , Validation Accuracy: 0.9275\n"," Iteration 159 , Validation Accuracy: 0.9281\n"," Iteration 160 , Validation Accuracy: 0.929\n"," Iteration 161 , Validation Accuracy: 0.9298\n"," Iteration 162 , Validation Accuracy: 0.9302\n"," Iteration 163 , Validation Accuracy: 0.9304\n"," Iteration 164 , Validation Accuracy: 0.9308\n"," Iteration 165 , Validation Accuracy: 0.9314\n"," Iteration 166 , Validation Accuracy: 0.9313\n"," Iteration 167 , Validation Accuracy: 0.9318\n"," Iteration 168 , Validation Accuracy: 0.9326\n"," Iteration 169 , Validation Accuracy: 0.9329\n"," Iteration 170 , Validation Accuracy: 0.9337\n"," Iteration 171 , Validation Accuracy: 0.934\n"," Iteration 172 , Validation Accuracy: 0.9346\n"," Iteration 173 , Validation Accuracy: 0.9347\n"," Iteration 174 , Validation Accuracy: 0.9354\n"," Iteration 175 , Validation Accuracy: 0.936\n"," Iteration 176 , Validation Accuracy: 0.9363\n"," Iteration 177 , Validation Accuracy: 0.9371\n"," Iteration 178 , Validation Accuracy: 0.9373\n"," Iteration 179 , Validation Accuracy: 0.9384\n"," Iteration 180 , Validation Accuracy: 0.9383\n"," Iteration 181 , Validation Accuracy: 0.9387\n"," Iteration 182 , Validation Accuracy: 0.9392\n"," Iteration 183 , Validation Accuracy: 0.9399\n"," Iteration 184 , Validation Accuracy: 0.9405\n"," Iteration 185 , Validation Accuracy: 0.9409\n"," Iteration 186 , Validation Accuracy: 0.9419\n"," Iteration 187 , Validation Accuracy: 0.9419\n"," Iteration 188 , Validation Accuracy: 0.9422\n"," Iteration 189 , Validation Accuracy: 0.9427\n"," Iteration 190 , Validation Accuracy: 0.9432\n"," Iteration 191 , Validation Accuracy: 0.9436\n"," Iteration 192 , Validation Accuracy: 0.9439\n"," Iteration 193 , Validation Accuracy: 0.9444\n"," Iteration 194 , Validation Accuracy: 0.9446\n"," Iteration 195 , Validation Accuracy: 0.945\n"," Iteration 196 , Validation Accuracy: 0.9451\n"," Iteration 197 , Validation Accuracy: 0.9457\n"," Iteration 198 , Validation Accuracy: 0.9458\n"," Iteration 199 , Validation Accuracy: 0.9465\n"]}]},{"cell_type":"markdown","source":["# Final Thought\n","\n","While I manage to get around 94% validation accuracy after 200 rounds of training (it still seems to be increasing with more training iteration), I find that it's quite difficult to please neural network and get that correct configuration to work."],"metadata":{"id":"lc4tWnS0e1E0"}}]}